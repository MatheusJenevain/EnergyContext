{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = r\"D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\pdf\\appendixa_0.pdf\"\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    raise FileNotFoundError(\"Upload a PDF file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 3/3 [00:08<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an electrical engineer. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database, and only the database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide an answer combining the most important points of these five versions.\n",
    "    Original question: {question}\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"mistral\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The technologies used to provide indoor environmental comfort include, but are not limited to:\\n1. Heating, Ventilating and Air Conditioning (HVAC) systems: These systems control the temperature, humidity, and air quality in buildings by regulating the movement of air, heating or cooling it as necessary. Examples include furnaces, boilers, heat pumps, air conditioners, and ventilation systems.\\n2. Energy Efficient Appliances: High-efficiency appliances such as refrigerators, washing machines, and dryers can help maintain indoor comfort while minimizing energy consumption.\\n3. Lighting Systems: Efficient lighting design and control strategies can improve indoor comfort by reducing glare and ensuring adequate light levels for various activities.\\n4. Building Envelope Technologies: Insulation, windows, doors, and other building envelope components help to regulate temperature and prevent heat loss or gain, contributing to indoor environmental comfort.\\n5. Combined Heat and Power (CHP) Systems: CHP systems generate electricity while capturing the thermal energy produced as a byproduct, which can be used for space heating and hot water, further improving indoor comfort in buildings.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are technologies used to provide indoor environmental comfort?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is the relationship between Megawatt (MW) and Megawatt-hour (MWh)?\",\n",
    "    # Add more handwritten test queries here\n",
    "]\n",
    "\n",
    "expected_answers = [\n",
    "    \"A megawatt (MW) is a unit of power representing the rate at which energy is used or generated, while a megawatt-hour (MWh) is a unit of energy representing the total amount of energy used or generated over an hour.\",\n",
    "    # Add more expected answers corresponding to the handwritten test queries\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [' The relationship between Megawatt (MW) and Megawatt-hour (MWh) can be understood by considering the time aspect of power consumption. One MegaWatt (MW) is a measure of power, which represents one million watts. It signifies the rate at which energy is being used or produced per second.\\n\\nOn the other hand, Megawatt-hour (MWh) is a measure of energy, representing one million watt-hours. An hour (h) represents the time it takes for this much power to be delivered continuously for 3600 seconds (since 1 hour = 3600 seconds). Therefore, if you use or produce 1 MW of power for 1 hour, you have consumed or produced 1 MWh.\\n\\nIn other words, 1 MW is equivalent to 1 MWh in 1 hour, but when power is consumed or produced over a different amount of time, the number of MWh will change accordingly (e.g., using or producing 1 MW for 30 minutes would be 0.5 MWh).']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.06 (low)\n",
      "Average ROUGE-1 Score: 0.33 (mid)\n",
      "Average ROUGE-2 Score: 0.21 (mid)\n",
      "Average ROUGE-L Score: 0.29 (mid)\n",
      "Average Semantic Similarity: 0.88 (high)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Define a set of handwritten test queries and expected answers\n",
    "test_queries = [\n",
    "    \"What is the relationship between Megawatt (MW) and Megawatt-hour (MWh)?\",\n",
    "    # Add more handwritten test queries here\n",
    "]\n",
    "\n",
    "expected_answers = [\n",
    "    \"A megawatt (MW) is a unit of power representing the rate at which energy is used or generated, while a megawatt-hour (MWh) is a unit of energy representing the total amount of energy used or generated over an hour.\",\n",
    "    # Add more expected answers corresponding to the handwritten test queries\n",
    "]\n",
    "\n",
    "# Function to categorize scores into low, mid, and high\n",
    "def categorize_score(score, thresholds):\n",
    "    if score < thresholds['low']:\n",
    "        return 'low'\n",
    "    elif score < thresholds['mid']:\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "# Function to evaluate the RAG system using BLEU, ROUGE, and semantic similarity\n",
    "def evaluate_rag_system(chain, test_queries, expected_answers):\n",
    "    # Get predictions from the RAG system\n",
    "    predictions = [chain.invoke(query) for query in test_queries]\n",
    "    print(\"Predictions:\", predictions)  # Debug: Print predictions to see what the system returns\n",
    "\n",
    "    # Initialize metrics\n",
    "    bleu_scores = []\n",
    "    rouge_scores = []\n",
    "    semantic_similarities = []\n",
    "\n",
    "    # Initialize ROUGE scorer\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Load a sentence transformer model for semantic similarity\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    for pred, ref in zip(predictions, expected_answers):\n",
    "        # Calculate BLEU score\n",
    "        bleu_score = sentence_bleu([ref.split()], pred.split(), smoothing_function=SmoothingFunction().method1)\n",
    "        bleu_scores.append(bleu_score)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        rouge_score = rouge.score(ref, pred)\n",
    "        rouge_scores.append(rouge_score)\n",
    "        \n",
    "        # Calculate semantic similarity\n",
    "        pred_embedding = model.encode(pred, convert_to_tensor=True)\n",
    "        ref_embedding = model.encode(ref, convert_to_tensor=True)\n",
    "        semantic_similarity = util.pytorch_cos_sim(pred_embedding, ref_embedding).item()\n",
    "        semantic_similarities.append(semantic_similarity)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    avg_bleu = np.mean(bleu_scores)\n",
    "    avg_rouge1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n",
    "    avg_rouge2 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n",
    "    avg_rougeL = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
    "    avg_semantic_similarity = np.mean(semantic_similarities)\n",
    "\n",
    "    # Define thresholds for categorizing scores\n",
    "    thresholds = {\n",
    "        'bleu': {'low': 0.2, 'mid': 0.5},\n",
    "        'rouge1': {'low': 0.2, 'mid': 0.5},\n",
    "        'rouge2': {'low': 0.1, 'mid': 0.3},\n",
    "        'rougeL': {'low': 0.2, 'mid': 0.5},\n",
    "        'semantic': {'low': 0.5, 'mid': 0.7}\n",
    "    }\n",
    "\n",
    "    # Categorize the average scores\n",
    "    bleu_category = categorize_score(avg_bleu, thresholds['bleu'])\n",
    "    rouge1_category = categorize_score(avg_rouge1, thresholds['rouge1'])\n",
    "    rouge2_category = categorize_score(avg_rouge2, thresholds['rouge2'])\n",
    "    rougeL_category = categorize_score(avg_rougeL, thresholds['rougeL'])\n",
    "    semantic_category = categorize_score(avg_semantic_similarity, thresholds['semantic'])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average BLEU Score: {avg_bleu:.2f} ({bleu_category})\")\n",
    "    print(f\"Average ROUGE-1 Score: {avg_rouge1:.2f} ({rouge1_category})\")\n",
    "    print(f\"Average ROUGE-2 Score: {avg_rouge2:.2f} ({rouge2_category})\")\n",
    "    print(f\"Average ROUGE-L Score: {avg_rougeL:.2f} ({rougeL_category})\")\n",
    "    print(f\"Average Semantic Similarity: {avg_semantic_similarity:.2f} ({semantic_category})\")\n",
    "\n",
    "    return {\n",
    "        'avg_bleu': avg_bleu,\n",
    "        'avg_rouge1': avg_rouge1,\n",
    "        'avg_rouge2': avg_rouge2,\n",
    "        'avg_rougeL': avg_rougeL,\n",
    "        'avg_semantic_similarity': avg_semantic_similarity,\n",
    "        'categories': {\n",
    "            'bleu': bleu_category,\n",
    "            'rouge1': rouge1_category,\n",
    "            'rouge2': rouge2_category,\n",
    "            'rougeL': rougeL_category,\n",
    "            'semantic': semantic_category\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Assuming 'chain' is your RAG system already defined\n",
    "# For example, chain.invoke(\"Your query\") should return the answer from the RAG system\n",
    "evaluation_results = evaluate_rag_system(chain, test_queries, expected_answers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
