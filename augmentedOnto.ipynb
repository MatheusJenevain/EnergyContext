{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from owlready2 import get_ontology\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ontology...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path-\n",
    "directory = 'D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\ontology\\imports'\n",
    "filename = 'oec-extracted.owl'\n",
    "file_path = os.path.join(directory, filename)\n",
    "\n",
    "print(\"Loading ontology...\")\n",
    "# Load the ontology\n",
    "onto = get_ontology(\"file://\" + file_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the IRIs for the properties and the individual\n",
    "term_sent_by_property_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#termSentBy\"\n",
    "actor_coal_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#actorCoal\"\n",
    "actor_has_context_property_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#actorHasContext\"\n",
    "\n",
    "# Search for the properties and the individual in the ontology\n",
    "term_sent_by_property = onto.search_one(iri=term_sent_by_property_iri)\n",
    "actor_coal = onto.search_one(iri=actor_coal_iri)\n",
    "actor_has_context_property = onto.search_one(iri=actor_has_context_property_iri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 3/3 [00:08<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "local_path = r\"D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\pdf\\appendixa_0.pdf\"\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    raise FileNotFoundError(\"Upload a PDF file\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"answer_prompt_template = You are an expert in electrial engineering.\n",
    "    Using only the information provided in the context, choose the best answer, and only that, to the following question:\n",
    "    Original question: {question}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = \"mistral\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based ONLY on the following context with ONLY one answer:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual: D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\ontology\\imports\\oec-extracted.ExchangedTermNetMetering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is net metering?\n",
      "net metering :  Net metering is a system that allows consumers who generate their own electricity from renewable energy sources (such as solar panels) to feed excess electricity back into the grid, effectively crediting them for the excess power they produce. This means that during periods when the consumer's on-site generation exceeds their electrical demand, the utility credit is applied to the customer's next bill in proportion to the amount of electricity fed onto the grid. The goal of net metering is to encourage the use of renewable energy by reducing the financial burden for consumers who want to invest in such systems.\n",
      "Individual: D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\ontology\\imports\\oec-extracted.ExchangedTermStorage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Storage?\n",
      "Storage :  Storage in the context of renewable energy refers to technologies or systems that store electrical energy for later use, such as batteries, pumped hydroelectric storage, and thermal energy storage. The goal of storage is to manage the intermittent nature of renewable energy sources like solar and wind by storing excess energy produced during periods of low demand or high generation, and releasing it during periods of high demand or low generation. This helps ensure a stable electricity supply and improves the overall efficiency and reliability of the grid.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more of the properties or the individual could not be found in the ontology.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m onto\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\namespace.py:1092\u001b[0m, in \u001b[0;36mOntology.save\u001b[1;34m(self, file, format, **kargs)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrdfxml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs):\n\u001b[0;32m   1091\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m   file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1092\u001b[0m     file \u001b[38;5;241m=\u001b[39m _open_onto_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_iri, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _LOG_LEVEL: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m* Owlready2 * Saving ontology \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mgetattr\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m???\u001b[39m\u001b[38;5;124m\"\u001b[39m)), file \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39msave(file, \u001b[38;5;28mformat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\namespace.py:1418\u001b[0m, in \u001b[0;36m_open_onto_file\u001b[1;34m(base_iri, name, mode, only_local)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filename) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filename): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, mode)\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (mode\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_local: \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(base_iri)\n\u001b[1;32m-> 1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (mode\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(onto_path[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.owl\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name), mode)\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Check if the properties and individual exist\n",
    "if term_sent_by_property and actor_coal and actor_has_context_property:\n",
    "    # List to store individuals with 'termSentBy' set to 'actorCoal'\n",
    "    individuals_with_term_sent_by_actor_coal = []\n",
    "\n",
    "    # Iterate through all individuals in the ontology\n",
    "    for individual in onto.individuals():\n",
    "        # Check if the individual has the property 'termSentBy'\n",
    "        if term_sent_by_property in individual.get_properties():\n",
    "            # Retrieve the values of 'termSentBy'\n",
    "            term_sent_by_values = getattr(individual, term_sent_by_property.python_name)\n",
    "            # Check if 'actorCoal' is in the values of 'termSentBy'\n",
    "            if actor_coal in term_sent_by_values:\n",
    "                individuals_with_term_sent_by_actor_coal.append(individual)\n",
    "\n",
    "    #print(\"Individuals where 'termSentBy' is 'actorCoal':\")\n",
    "    for individual in individuals_with_term_sent_by_actor_coal:\n",
    "        print(f\"Individual: {individual}\")\n",
    "\n",
    "        # Check if the individual has the 'termLexiconString' data property\n",
    "        if hasattr(individual, \"termLexiconString\"):\n",
    "            # Retrieve the value of 'termLexiconString'\n",
    "            term_lexicon_string_value = getattr(individual, \"termLexiconString\")\n",
    "            \n",
    "            # Check if the value is a list and convert it to a string\n",
    "            if isinstance(term_lexicon_string_value, list):\n",
    "                term_lexicon_string_value = \" \".join(term_lexicon_string_value)\n",
    "            \n",
    "            # Check if the value is empty or not\n",
    "            if term_lexicon_string_value:\n",
    "                lexicon_question = \"What is \" +  term_lexicon_string_value + \"?\"\n",
    "                answer = chain.invoke(lexicon_question)\n",
    "                if hasattr(individual, \"termMeaningString\"):\n",
    "                        # Retrieve the current value of 'termMeaningString'\n",
    "                        term_meaning_string_value = getattr(individual, \"termMeaningString\")\n",
    "                        \n",
    "                        # Check if it's a list, if not make it a list\n",
    "                        if not isinstance(term_meaning_string_value, list):\n",
    "                            term_meaning_string_value = [term_meaning_string_value]\n",
    "                        \n",
    "                        # Append the new answer\n",
    "                        \n",
    "                        term_meaning_string_value.append(answer)\n",
    "\n",
    "                        # Set the updated value back to 'termMeaningString'\n",
    "                        setattr(individual, \"termMeaningString\", term_meaning_string_value)\n",
    "                else:\n",
    "                        print(\"  termMeaningString: Not found\")\n",
    "                # Print the answer\n",
    "                print(\"Question:\", lexicon_question)\n",
    "                print(term_lexicon_string_value,\":\", answer)\n",
    "                \n",
    "            else:\n",
    "                print(\"  termLexiconString is empty\")\n",
    "        else:\n",
    "            print(\"  termLexiconString: Not found\")\n",
    "\n",
    "else:\n",
    "    print(\"One or more of the properties or the individual could not be found in the ontology.\")\n",
    "onto.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
