{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from owlready2 import get_ontology\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ontology...\n"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "directory = 'D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\ontology\\imports'\n",
    "filename = 'oec-extracted.owl'\n",
    "file_path = os.path.join(directory, filename)\n",
    "\n",
    "print(\"Loading ontology...\")\n",
    "# Load the ontology\n",
    "onto = get_ontology(\"file://\" + file_path).load()\n",
    "\n",
    "# Define the IRIs (unique identifiers) for properties and individual in the ontology\n",
    "term_sent_by_property_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#termSentBy\"\n",
    "actor_coal_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#actorCoal\"\n",
    "actor_has_context_property_iri = \"http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#actorHasContext\"\n",
    "\n",
    "# Get the ontology elements (properties and individual) using their IRIs\n",
    "term_sent_by_property = onto.search_one(iri=term_sent_by_property_iri)\n",
    "actor_coal = onto.search_one(iri=actor_coal_iri)\n",
    "actor_has_context_property = onto.search_one(iri=actor_has_context_property_iri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF file\n",
    "local_path = r\"D:\\GitHub\\Projetos\\Mestrado\\EnergyContext\\pdf\\appendixa_0.pdf\"\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    raise FileNotFoundError(\"Upload a PDF file\")\n",
    "\n",
    "# Split PDF into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Create the vector database using the Ollama Embeddings model\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template for querying the context\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"answer_prompt_template = You are an expert in electrial engineering.\n",
    "    Using only the information provided in the context, choose the best answer, and only that, to the following question:\n",
    "    Original question: {question}\"\"\")\n",
    "local_model = \"mistral\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template for formatting the question and context\n",
    "template = \"\"\"Answer the question based ONLY on the following context with ONLY one answer:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Set up a chain to retrieve relevant context, format the question and answer using the template, and generate a response using the language model\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is net metering?\n",
      "net metering :  Net metering is a policy or program that allows renewable energy system owners to receive credits for surplus electricity their systems produce but do not use, and which are fed back into the grid. These credits can be used to offset electricity costs when the system's output does not meet demand (e.g., during nighttime). It encourages the deployment of renewable energy technologies by allowing consumers to benefit financially from their own production. The specific details of net metering policies, such as the amount and duration of credits, can vary depending on the jurisdiction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Storage?\n",
      "Storage :  Storage in the context of renewable energy refers to technologies and systems designed to store excess electrical energy generated by renewable sources (such as solar, wind, or geothermal) for later use. This stored energy can help balance supply and demand, ensure a consistent power output during periods when generation may be low (e.g., at night or on calm days), and reduce the reliance on traditional fossil fuel-based power plants. Some common storage technologies include batteries, pumped hydroelectric storage, and thermal storage systems. The storage of renewable energy is an essential aspect of a sustainable and resilient electricity grid.\n"
     ]
    }
   ],
   "source": [
    "# List to store individual IRIs to be updated\n",
    "individuals_to_update = []\n",
    "\n",
    "# First Loop: Collect Individuals to Update\n",
    "if term_sent_by_property and actor_coal and actor_has_context_property:\n",
    "    for individual in onto.individuals():\n",
    "        if term_sent_by_property in individual.get_properties():\n",
    "            term_sent_by_values = getattr(individual, term_sent_by_property.python_name)\n",
    "            if actor_coal in term_sent_by_values:\n",
    "                individuals_to_update.append(individual.iri) \n",
    "\n",
    "# Second Loop: Perform Question-Answering and Update Ontology\n",
    "with onto:   \n",
    "    for individual_iri in individuals_to_update:\n",
    "        try: \n",
    "            individual = onto.search_one(iri=individual_iri)\n",
    "            if not individual:\n",
    "                print(f\"Warning: Individual with IRI {individual_iri} not found.\")\n",
    "                continue  # Skip to the next individual if not found\n",
    "\n",
    "            if hasattr(individual, \"termLexiconString\"):\n",
    "                term_lexicon_string_value = getattr(individual, \"termLexiconString\")\n",
    "                if isinstance(term_lexicon_string_value, list):\n",
    "                    term_lexicon_string_value = \" \".join(term_lexicon_string_value)\n",
    "                if term_lexicon_string_value:\n",
    "                    lexicon_question = \"What is \" + term_lexicon_string_value + \"?\"\n",
    "                    answer = chain.invoke(lexicon_question)\n",
    "                    print(\"Question:\", lexicon_question)\n",
    "                    print(term_lexicon_string_value, \":\", answer)\n",
    "                    # Update the termMeaningString property\n",
    "                    individual.termMeaningString.append(answer)\n",
    "\n",
    "            else:\n",
    "                print(\" termLexiconString is empty\")\n",
    "        except Exception as e:  # Catch any unexpected errors\n",
    "            print(f\"Error processing individual {individual_iri}: {e}\")\n",
    "    \n",
    "\n",
    "# Save the updated ontology (handle empty onto_path)\n",
    "try:\n",
    "    onto.save(file_path) \n",
    "except IndexError:  # If onto_path is still empty after modifications\n",
    "    print(\"Error: Unable to determine save location. Using default path.\")\n",
    "    onto.save(file_path) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
